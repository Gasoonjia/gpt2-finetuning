[
  {
    "loss": 4619.191,
    "learning_rate": 4.971982517090665e-05,
    "epoch": 0.05603496581867085,
    "total_flos": 30121183488000,
    "step": 500
  },
  {
    "loss": 3609.72,
    "learning_rate": 4.943965034181329e-05,
    "epoch": 0.1120699316373417,
    "total_flos": 60242366976000,
    "step": 1000
  },
  {
    "loss": 3589.847,
    "learning_rate": 4.915947551271994e-05,
    "epoch": 0.16810489745601256,
    "total_flos": 90363550464000,
    "step": 1500
  },
  {
    "loss": 3564.068,
    "learning_rate": 4.887930068362658e-05,
    "epoch": 0.2241398632746834,
    "total_flos": 120484733952000,
    "step": 2000
  },
  {
    "loss": 3557.368,
    "learning_rate": 4.859912585453323e-05,
    "epoch": 0.2801748290933542,
    "total_flos": 150605917440000,
    "step": 2500
  },
  {
    "loss": 3545.878,
    "learning_rate": 4.831895102543988e-05,
    "epoch": 0.33620979491202513,
    "total_flos": 180727100928000,
    "step": 3000
  },
  {
    "loss": 3565.956,
    "learning_rate": 4.8038776196346526e-05,
    "epoch": 0.392244760730696,
    "total_flos": 210848284416000,
    "step": 3500
  },
  {
    "loss": 3548.444,
    "learning_rate": 4.775860136725317e-05,
    "epoch": 0.4482797265493668,
    "total_flos": 240969467904000,
    "step": 4000
  },
  {
    "loss": 3545.668,
    "learning_rate": 4.7478426538159815e-05,
    "epoch": 0.5043146923680376,
    "total_flos": 271090651392000,
    "step": 4500
  },
  {
    "loss": 3529.136,
    "learning_rate": 4.719825170906646e-05,
    "epoch": 0.5603496581867085,
    "total_flos": 301211834880000,
    "step": 5000
  },
  {
    "eval_loss": 3540.8194136695984,
    "epoch": 0.5603496581867085,
    "total_flos": 301211834880000,
    "step": 5000
  },
  {
    "loss": 3538.744,
    "learning_rate": 4.6918076879973105e-05,
    "epoch": 0.6163846240053794,
    "total_flos": 331333018368000,
    "step": 5500
  },
  {
    "loss": 3541.376,
    "learning_rate": 4.663790205087975e-05,
    "epoch": 0.6724195898240503,
    "total_flos": 361454201856000,
    "step": 6000
  },
  {
    "loss": 3536.612,
    "learning_rate": 4.6357727221786394e-05,
    "epoch": 0.7284545556427211,
    "total_flos": 391575385344000,
    "step": 6500
  },
  {
    "loss": 3532.212,
    "learning_rate": 4.607755239269304e-05,
    "epoch": 0.784489521461392,
    "total_flos": 421696568832000,
    "step": 7000
  },
  {
    "loss": 3520.18,
    "learning_rate": 4.5797377563599684e-05,
    "epoch": 0.8405244872800628,
    "total_flos": 451817752320000,
    "step": 7500
  },
  {
    "loss": 3540.34,
    "learning_rate": 4.551720273450634e-05,
    "epoch": 0.8965594530987336,
    "total_flos": 481938935808000,
    "step": 8000
  },
  {
    "loss": 3515.828,
    "learning_rate": 4.523702790541298e-05,
    "epoch": 0.9525944189174045,
    "total_flos": 512060119296000,
    "step": 8500
  },
  {
    "loss": 3519.064,
    "learning_rate": 4.495685307631963e-05,
    "epoch": 1.0086293847360752,
    "total_flos": 542181302784000,
    "step": 9000
  },
  {
    "loss": 3536.4,
    "learning_rate": 4.467667824722627e-05,
    "epoch": 1.0646643505547462,
    "total_flos": 572302486272000,
    "step": 9500
  },
  {
    "loss": 3513.36,
    "learning_rate": 4.439650341813292e-05,
    "epoch": 1.120699316373417,
    "total_flos": 602423669760000,
    "step": 10000
  },
  {
    "eval_loss": 3524.436536598056,
    "epoch": 1.120699316373417,
    "total_flos": 602423669760000,
    "step": 10000
  },
  {
    "loss": 3537.608,
    "learning_rate": 4.4116328589039566e-05,
    "epoch": 1.1767342821920879,
    "total_flos": 632544853248000,
    "step": 10500
  },
  {
    "loss": 3543.112,
    "learning_rate": 4.383615375994621e-05,
    "epoch": 1.2327692480107588,
    "total_flos": 662666036736000,
    "step": 11000
  },
  {
    "loss": 3508.68,
    "learning_rate": 4.3555978930852855e-05,
    "epoch": 1.2888042138294296,
    "total_flos": 692787220224000,
    "step": 11500
  },
  {
    "loss": 3532.496,
    "learning_rate": 4.32758041017595e-05,
    "epoch": 1.3448391796481003,
    "total_flos": 722908403712000,
    "step": 12000
  },
  {
    "loss": 3523.384,
    "learning_rate": 4.2995629272666145e-05,
    "epoch": 1.4008741454667712,
    "total_flos": 753029587200000,
    "step": 12500
  },
  {
    "loss": 3519.608,
    "learning_rate": 4.2715454443572786e-05,
    "epoch": 1.4569091112854422,
    "total_flos": 783150770688000,
    "step": 13000
  },
  {
    "loss": 3540.16,
    "learning_rate": 4.243527961447944e-05,
    "epoch": 1.512944077104113,
    "total_flos": 813271954176000,
    "step": 13500
  },
  {
    "loss": 3518.072,
    "learning_rate": 4.215510478538608e-05,
    "epoch": 1.5689790429227837,
    "total_flos": 843393137664000,
    "step": 14000
  },
  {
    "loss": 3522.808,
    "learning_rate": 4.187492995629273e-05,
    "epoch": 1.6250140087414546,
    "total_flos": 873514321152000,
    "step": 14500
  },
  {
    "loss": 3533.4,
    "learning_rate": 4.159475512719937e-05,
    "epoch": 1.6810489745601256,
    "total_flos": 903635504640000,
    "step": 15000
  },
  {
    "eval_loss": 3520.242468605097,
    "epoch": 1.6810489745601256,
    "total_flos": 903635504640000,
    "step": 15000
  },
  {
    "loss": 3507.928,
    "learning_rate": 4.131458029810602e-05,
    "epoch": 1.7370839403787963,
    "total_flos": 933756688128000,
    "step": 15500
  },
  {
    "loss": 3512.104,
    "learning_rate": 4.103440546901267e-05,
    "epoch": 1.793118906197467,
    "total_flos": 963877871616000,
    "step": 16000
  },
  {
    "loss": 3536.808,
    "learning_rate": 4.075423063991931e-05,
    "epoch": 1.8491538720161382,
    "total_flos": 993999055104000,
    "step": 16500
  },
  {
    "loss": 3508.648,
    "learning_rate": 4.047405581082596e-05,
    "epoch": 1.905188837834809,
    "total_flos": 1024120238592000,
    "step": 17000
  },
  {
    "loss": 3522.744,
    "learning_rate": 4.01938809817326e-05,
    "epoch": 1.9612238036534797,
    "total_flos": 1054241422080000,
    "step": 17500
  },
  {
    "loss": 3525.4,
    "learning_rate": 3.991370615263925e-05,
    "epoch": 2.0172587694721504,
    "total_flos": 1084362605568000,
    "step": 18000
  },
  {
    "loss": 3505.344,
    "learning_rate": 3.9633531323545895e-05,
    "epoch": 2.0732937352908216,
    "total_flos": 1114483789056000,
    "step": 18500
  },
  {
    "loss": 3512.816,
    "learning_rate": 3.9353356494452543e-05,
    "epoch": 2.1293287011094923,
    "total_flos": 1144604972544000,
    "step": 19000
  },
  {
    "loss": 3518.608,
    "learning_rate": 3.9073181665359185e-05,
    "epoch": 2.185363666928163,
    "total_flos": 1174726156032000,
    "step": 19500
  },
  {
    "loss": 3536.096,
    "learning_rate": 3.879300683626583e-05,
    "epoch": 2.241398632746834,
    "total_flos": 1204847339520000,
    "step": 20000
  },
  {
    "eval_loss": 3514.9987098003844,
    "epoch": 2.241398632746834,
    "total_flos": 1204847339520000,
    "step": 20000
  },
  {
    "loss": 3508.624,
    "learning_rate": 3.851283200717248e-05,
    "epoch": 2.297433598565505,
    "total_flos": 1234968523008000,
    "step": 20500
  },
  {
    "loss": 3521.888,
    "learning_rate": 3.823265717807912e-05,
    "epoch": 2.3534685643841757,
    "total_flos": 1265089706496000,
    "step": 21000
  },
  {
    "loss": 3507.456,
    "learning_rate": 3.795248234898577e-05,
    "epoch": 2.4095035302028465,
    "total_flos": 1295210889984000,
    "step": 21500
  },
  {
    "loss": 3518.512,
    "learning_rate": 3.767230751989241e-05,
    "epoch": 2.4655384960215176,
    "total_flos": 1325332073472000,
    "step": 22000
  },
  {
    "loss": 3529.36,
    "learning_rate": 3.739213269079906e-05,
    "epoch": 2.5215734618401884,
    "total_flos": 1355453256960000,
    "step": 22500
  },
  {
    "loss": 3516.048,
    "learning_rate": 3.71119578617057e-05,
    "epoch": 2.577608427658859,
    "total_flos": 1385574440448000,
    "step": 23000
  },
  {
    "loss": 3519.392,
    "learning_rate": 3.683178303261235e-05,
    "epoch": 2.63364339347753,
    "total_flos": 1415695623936000,
    "step": 23500
  },
  {
    "loss": 3528.576,
    "learning_rate": 3.6551608203519e-05,
    "epoch": 2.6896783592962006,
    "total_flos": 1445816807424000,
    "step": 24000
  },
  {
    "loss": 3513.76,
    "learning_rate": 3.6271433374425646e-05,
    "epoch": 2.7457133251148718,
    "total_flos": 1475937990912000,
    "step": 24500
  },
  {
    "loss": 3529.488,
    "learning_rate": 3.599125854533229e-05,
    "epoch": 2.8017482909335425,
    "total_flos": 1506059174400000,
    "step": 25000
  },
  {
    "eval_loss": 3512.852505353966,
    "epoch": 2.8017482909335425,
    "total_flos": 1506059174400000,
    "step": 25000
  },
  {
    "loss": 3528.048,
    "learning_rate": 3.5711083716238935e-05,
    "epoch": 2.8577832567522132,
    "total_flos": 1536180357888000,
    "step": 25500
  },
  {
    "loss": 3505.44,
    "learning_rate": 3.5430908887145583e-05,
    "epoch": 2.9138182225708844,
    "total_flos": 1566301541376000,
    "step": 26000
  },
  {
    "loss": 3518.64,
    "learning_rate": 3.5150734058052225e-05,
    "epoch": 2.969853188389555,
    "total_flos": 1596422724864000,
    "step": 26500
  },
  {
    "loss": 3519.056,
    "learning_rate": 3.487055922895887e-05,
    "epoch": 3.025888154208226,
    "total_flos": 1626543908352000,
    "step": 27000
  },
  {
    "loss": 3520.032,
    "learning_rate": 3.4590384399865514e-05,
    "epoch": 3.0819231200268966,
    "total_flos": 1656665091840000,
    "step": 27500
  },
  {
    "loss": 3488.384,
    "learning_rate": 3.431020957077216e-05,
    "epoch": 3.137958085845568,
    "total_flos": 1686786275328000,
    "step": 28000
  },
  {
    "loss": 3515.552,
    "learning_rate": 3.4030034741678804e-05,
    "epoch": 3.1939930516642385,
    "total_flos": 1716907458816000,
    "step": 28500
  },
  {
    "loss": 3500.976,
    "learning_rate": 3.374985991258546e-05,
    "epoch": 3.2500280174829093,
    "total_flos": 1747028642304000,
    "step": 29000
  },
  {
    "loss": 3534.736,
    "learning_rate": 3.34696850834921e-05,
    "epoch": 3.30606298330158,
    "total_flos": 1777149825792000,
    "step": 29500
  },
  {
    "loss": 3516.272,
    "learning_rate": 3.318951025439875e-05,
    "epoch": 3.362097949120251,
    "total_flos": 1807271009280000,
    "step": 30000
  },
  {
    "eval_loss": 3511.10498246609,
    "epoch": 3.362097949120251,
    "total_flos": 1807271009280000,
    "step": 30000
  },
  {
    "loss": 3510.432,
    "learning_rate": 3.2909335425305396e-05,
    "epoch": 3.418132914938922,
    "total_flos": 1837392192768000,
    "step": 30500
  },
  {
    "loss": 3512.704,
    "learning_rate": 3.262916059621204e-05,
    "epoch": 3.4741678807575926,
    "total_flos": 1867513376256000,
    "step": 31000
  },
  {
    "loss": 3501.696,
    "learning_rate": 3.2348985767118686e-05,
    "epoch": 3.5302028465762634,
    "total_flos": 1897634559744000,
    "step": 31500
  },
  {
    "loss": 3507.328,
    "learning_rate": 3.206881093802533e-05,
    "epoch": 3.5862378123949346,
    "total_flos": 1927755743232000,
    "step": 32000
  },
  {
    "loss": 3522.4,
    "learning_rate": 3.1788636108931975e-05,
    "epoch": 3.6422727782136053,
    "total_flos": 1957876926720000,
    "step": 32500
  },
  {
    "loss": 3504.64,
    "learning_rate": 3.1508461279838617e-05,
    "epoch": 3.698307744032276,
    "total_flos": 1987998110208000,
    "step": 33000
  },
  {
    "loss": 3515.504,
    "learning_rate": 3.1228286450745265e-05,
    "epoch": 3.754342709850947,
    "total_flos": 2018119293696000,
    "step": 33500
  },
  {
    "loss": 3506.64,
    "learning_rate": 3.094811162165191e-05,
    "epoch": 3.810377675669618,
    "total_flos": 2048240477184000,
    "step": 34000
  },
  {
    "loss": 3531.408,
    "learning_rate": 3.066793679255856e-05,
    "epoch": 3.8664126414882887,
    "total_flos": 2078361660672000,
    "step": 34500
  },
  {
    "loss": 3510.992,
    "learning_rate": 3.0387761963465206e-05,
    "epoch": 3.9224476073069594,
    "total_flos": 2108482844160000,
    "step": 35000
  },
  {
    "eval_loss": 3508.804964774582,
    "epoch": 3.9224476073069594,
    "total_flos": 2108482844160000,
    "step": 35000
  },
  {
    "loss": 3519.104,
    "learning_rate": 3.010758713437185e-05,
    "epoch": 3.97848257312563,
    "total_flos": 2138604027648000,
    "step": 35500
  },
  {
    "loss": 3523.904,
    "learning_rate": 2.9827412305278495e-05,
    "epoch": 4.034517538944301,
    "total_flos": 2168725211136000,
    "step": 36000
  },
  {
    "loss": 3513.568,
    "learning_rate": 2.954723747618514e-05,
    "epoch": 4.0905525047629725,
    "total_flos": 2198846394624000,
    "step": 36500
  },
  {
    "loss": 3506.912,
    "learning_rate": 2.9267062647091785e-05,
    "epoch": 4.146587470581643,
    "total_flos": 2228967578112000,
    "step": 37000
  },
  {
    "loss": 3535.008,
    "learning_rate": 2.8986887817998433e-05,
    "epoch": 4.202622436400314,
    "total_flos": 2259088761600000,
    "step": 37500
  },
  {
    "loss": 3493.568,
    "learning_rate": 2.8706712988905078e-05,
    "epoch": 4.258657402218985,
    "total_flos": 2289209945088000,
    "step": 38000
  },
  {
    "loss": 3512.864,
    "learning_rate": 2.8426538159811722e-05,
    "epoch": 4.314692368037655,
    "total_flos": 2319331128576000,
    "step": 38500
  },
  {
    "loss": 3500.704,
    "learning_rate": 2.8146363330718367e-05,
    "epoch": 4.370727333856326,
    "total_flos": 2349452312064000,
    "step": 39000
  },
  {
    "loss": 3512.544,
    "learning_rate": 2.786618850162502e-05,
    "epoch": 4.426762299674997,
    "total_flos": 2379573495552000,
    "step": 39500
  },
  {
    "loss": 3495.936,
    "learning_rate": 2.7586013672531663e-05,
    "epoch": 4.482797265493668,
    "total_flos": 2409694679040000,
    "step": 40000
  },
  {
    "eval_loss": 3506.7182806524397,
    "epoch": 4.482797265493668,
    "total_flos": 2409694679040000,
    "step": 40000
  },
  {
    "loss": 3516.128,
    "learning_rate": 2.7305838843438308e-05,
    "epoch": 4.538832231312339,
    "total_flos": 2439815862528000,
    "step": 40500
  },
  {
    "loss": 3506.144,
    "learning_rate": 2.7025664014344953e-05,
    "epoch": 4.59486719713101,
    "total_flos": 2469937046016000,
    "step": 41000
  },
  {
    "loss": 3517.28,
    "learning_rate": 2.6745489185251598e-05,
    "epoch": 4.650902162949681,
    "total_flos": 2500058229504000,
    "step": 41500
  },
  {
    "loss": 3500.96,
    "learning_rate": 2.6465314356158242e-05,
    "epoch": 4.7069371287683515,
    "total_flos": 2530179412992000,
    "step": 42000
  },
  {
    "loss": 3521.664,
    "learning_rate": 2.618513952706489e-05,
    "epoch": 4.762972094587022,
    "total_flos": 2560300596480000,
    "step": 42500
  },
  {
    "loss": 3512.544,
    "learning_rate": 2.5904964697971535e-05,
    "epoch": 4.819007060405693,
    "total_flos": 2590421779968000,
    "step": 43000
  },
  {
    "loss": 3499.68,
    "learning_rate": 2.562478986887818e-05,
    "epoch": 4.875042026224364,
    "total_flos": 2620542963456000,
    "step": 43500
  },
  {
    "loss": 3505.184,
    "learning_rate": 2.5344615039784825e-05,
    "epoch": 4.931076992043035,
    "total_flos": 2650664146944000,
    "step": 44000
  },
  {
    "loss": 3510.816,
    "learning_rate": 2.506444021069147e-05,
    "epoch": 4.987111957861706,
    "total_flos": 2680785330432000,
    "step": 44500
  },
  {
    "loss": 3520.832,
    "learning_rate": 2.4784265381598118e-05,
    "epoch": 5.043146923680377,
    "total_flos": 2710906513920000,
    "step": 45000
  },
  {
    "eval_loss": 3505.702809392905,
    "epoch": 5.043146923680377,
    "total_flos": 2710906513920000,
    "step": 45000
  },
  {
    "loss": 3513.248,
    "learning_rate": 2.4504090552504762e-05,
    "epoch": 5.0991818894990475,
    "total_flos": 2741027697408000,
    "step": 45500
  },
  {
    "loss": 3502.912,
    "learning_rate": 2.422391572341141e-05,
    "epoch": 5.155216855317718,
    "total_flos": 2771148880896000,
    "step": 46000
  },
  {
    "loss": 3500.448,
    "learning_rate": 2.3943740894318055e-05,
    "epoch": 5.211251821136389,
    "total_flos": 2801270064384000,
    "step": 46500
  },
  {
    "loss": 3503.008,
    "learning_rate": 2.36635660652247e-05,
    "epoch": 5.26728678695506,
    "total_flos": 2831391247872000,
    "step": 47000
  },
  {
    "loss": 3514.304,
    "learning_rate": 2.3383391236131348e-05,
    "epoch": 5.32332175277373,
    "total_flos": 2861512431360000,
    "step": 47500
  },
  {
    "loss": 3514.08,
    "learning_rate": 2.3103216407037993e-05,
    "epoch": 5.379356718592402,
    "total_flos": 2891633614848000,
    "step": 48000
  },
  {
    "loss": 3503.648,
    "learning_rate": 2.282304157794464e-05,
    "epoch": 5.435391684411073,
    "total_flos": 2921754798336000,
    "step": 48500
  },
  {
    "loss": 3492.224,
    "learning_rate": 2.2542866748851286e-05,
    "epoch": 5.4914266502297435,
    "total_flos": 2951875981824000,
    "step": 49000
  },
  {
    "loss": 3506.88,
    "learning_rate": 2.226269191975793e-05,
    "epoch": 5.547461616048414,
    "total_flos": 2981997165312000,
    "step": 49500
  },
  {
    "loss": 3516.736,
    "learning_rate": 2.1982517090664575e-05,
    "epoch": 5.603496581867085,
    "total_flos": 3012118348800000,
    "step": 50000
  },
  {
    "eval_loss": 3504.7630775158386,
    "epoch": 5.603496581867085,
    "total_flos": 3012118348800000,
    "step": 50000
  },
  {
    "loss": 3509.92,
    "learning_rate": 2.170234226157122e-05,
    "epoch": 5.659531547685756,
    "total_flos": 3042239532288000,
    "step": 50500
  },
  {
    "loss": 3505.6,
    "learning_rate": 2.1422167432477865e-05,
    "epoch": 5.7155665135044265,
    "total_flos": 3072360715776000,
    "step": 51000
  },
  {
    "loss": 3500.448,
    "learning_rate": 2.1141992603384513e-05,
    "epoch": 5.771601479323097,
    "total_flos": 3102481899264000,
    "step": 51500
  },
  {
    "loss": 3514.528,
    "learning_rate": 2.0861817774291158e-05,
    "epoch": 5.827636445141769,
    "total_flos": 3132603082752000,
    "step": 52000
  },
  {
    "loss": 3516.672,
    "learning_rate": 2.0581642945197806e-05,
    "epoch": 5.8836714109604396,
    "total_flos": 3162724266240000,
    "step": 52500
  },
  {
    "loss": 3490.208,
    "learning_rate": 2.030146811610445e-05,
    "epoch": 5.93970637677911,
    "total_flos": 3192845449728000,
    "step": 53000
  },
  {
    "loss": 3501.216,
    "learning_rate": 2.0021293287011095e-05,
    "epoch": 5.995741342597781,
    "total_flos": 3222966633216000,
    "step": 53500
  },
  {
    "loss": 3503.136,
    "learning_rate": 1.9741118457917743e-05,
    "epoch": 6.051776308416452,
    "total_flos": 3253087816704000,
    "step": 54000
  },
  {
    "loss": 3511.68,
    "learning_rate": 1.9460943628824388e-05,
    "epoch": 6.1078112742351225,
    "total_flos": 3283209000192000,
    "step": 54500
  },
  {
    "loss": 3499.968,
    "learning_rate": 1.9180768799731033e-05,
    "epoch": 6.163846240053793,
    "total_flos": 3313330183680000,
    "step": 55000
  },
  {
    "eval_loss": 3502.5440228804337,
    "epoch": 6.163846240053793,
    "total_flos": 3313330183680000,
    "step": 55000
  },
  {
    "loss": 3518.752,
    "learning_rate": 1.8900593970637678e-05,
    "epoch": 6.219881205872465,
    "total_flos": 3343451367168000,
    "step": 55500
  },
  {
    "loss": 3504.384,
    "learning_rate": 1.8620419141544322e-05,
    "epoch": 6.275916171691136,
    "total_flos": 3373572550656000,
    "step": 56000
  },
  {
    "loss": 3500.64,
    "learning_rate": 1.834024431245097e-05,
    "epoch": 6.331951137509806,
    "total_flos": 3403693734144000,
    "step": 56500
  },
  {
    "loss": 3507.552,
    "learning_rate": 1.8060069483357615e-05,
    "epoch": 6.387986103328477,
    "total_flos": 3433814917632000,
    "step": 57000
  },
  {
    "loss": 3503.552,
    "learning_rate": 1.7779894654264263e-05,
    "epoch": 6.444021069147148,
    "total_flos": 3463936101120000,
    "step": 57500
  },
  {
    "loss": 3498.496,
    "learning_rate": 1.7499719825170908e-05,
    "epoch": 6.5000560349658185,
    "total_flos": 3494057284608000,
    "step": 58000
  },
  {
    "loss": 3513.056,
    "learning_rate": 1.7219544996077553e-05,
    "epoch": 6.556091000784489,
    "total_flos": 3524178468096000,
    "step": 58500
  },
  {
    "loss": 3502.56,
    "learning_rate": 1.69393701669842e-05,
    "epoch": 6.61212596660316,
    "total_flos": 3554299651584000,
    "step": 59000
  },
  {
    "loss": 3509.856,
    "learning_rate": 1.6659195337890846e-05,
    "epoch": 6.668160932421832,
    "total_flos": 3584420835072000,
    "step": 59500
  },
  {
    "loss": 3504.896,
    "learning_rate": 1.637902050879749e-05,
    "epoch": 6.724195898240502,
    "total_flos": 3614542018560000,
    "step": 60000
  },
  {
    "eval_loss": 3501.2784553108013,
    "epoch": 6.724195898240502,
    "total_flos": 3614542018560000,
    "step": 60000
  },
  {
    "loss": 3499.52,
    "learning_rate": 1.6098845679704135e-05,
    "epoch": 6.780230864059173,
    "total_flos": 3644663202048000,
    "step": 60500
  },
  {
    "loss": 3511.104,
    "learning_rate": 1.581867085061078e-05,
    "epoch": 6.836265829877844,
    "total_flos": 3674784385536000,
    "step": 61000
  },
  {
    "loss": 3512.672,
    "learning_rate": 1.5538496021517425e-05,
    "epoch": 6.8923007956965145,
    "total_flos": 3704905569024000,
    "step": 61500
  },
  {
    "loss": 3494.016,
    "learning_rate": 1.5258321192424075e-05,
    "epoch": 6.948335761515185,
    "total_flos": 3735026752512000,
    "step": 62000
  },
  {
    "loss": 3478.112,
    "learning_rate": 1.497814636333072e-05,
    "epoch": 7.004370727333856,
    "total_flos": 3765147936000000,
    "step": 62500
  },
  {
    "loss": 3509.6,
    "learning_rate": 1.4697971534237364e-05,
    "epoch": 7.060405693152527,
    "total_flos": 3795269119488000,
    "step": 63000
  },
  {
    "loss": 3521.152,
    "learning_rate": 1.441779670514401e-05,
    "epoch": 7.116440658971198,
    "total_flos": 3825390302976000,
    "step": 63500
  },
  {
    "loss": 3493.664,
    "learning_rate": 1.4137621876050655e-05,
    "epoch": 7.172475624789869,
    "total_flos": 3855511486464000,
    "step": 64000
  },
  {
    "loss": 3516.224,
    "learning_rate": 1.3857447046957303e-05,
    "epoch": 7.22851059060854,
    "total_flos": 3885632669952000,
    "step": 64500
  },
  {
    "loss": 3512.288,
    "learning_rate": 1.3577272217863948e-05,
    "epoch": 7.284545556427211,
    "total_flos": 3915753853440000,
    "step": 65000
  },
  {
    "eval_loss": 3500.2448387637637,
    "epoch": 7.284545556427211,
    "total_flos": 3915753853440000,
    "step": 65000
  },
  {
    "loss": 3503.84,
    "learning_rate": 1.3297097388770593e-05,
    "epoch": 7.340580522245881,
    "total_flos": 3945875036928000,
    "step": 65500
  },
  {
    "loss": 3495.2,
    "learning_rate": 1.301692255967724e-05,
    "epoch": 7.396615488064552,
    "total_flos": 3975996220416000,
    "step": 66000
  },
  {
    "loss": 3522.752,
    "learning_rate": 1.2736747730583884e-05,
    "epoch": 7.452650453883223,
    "total_flos": 4006117403904000,
    "step": 66500
  },
  {
    "loss": 3484.128,
    "learning_rate": 1.245657290149053e-05,
    "epoch": 7.508685419701894,
    "total_flos": 4036238587392000,
    "step": 67000
  },
  {
    "loss": 3494.784,
    "learning_rate": 1.2176398072397177e-05,
    "epoch": 7.564720385520565,
    "total_flos": 4066359770880000,
    "step": 67500
  },
  {
    "loss": 3492.96,
    "learning_rate": 1.1896223243303822e-05,
    "epoch": 7.620755351339236,
    "total_flos": 4096480954368000,
    "step": 68000
  },
  {
    "loss": 3514.976,
    "learning_rate": 1.1616048414210468e-05,
    "epoch": 7.676790317157907,
    "total_flos": 4126602137856000,
    "step": 68500
  },
  {
    "loss": 3486.912,
    "learning_rate": 1.1335873585117115e-05,
    "epoch": 7.732825282976577,
    "total_flos": 4156723321344000,
    "step": 69000
  },
  {
    "loss": 3514.08,
    "learning_rate": 1.105569875602376e-05,
    "epoch": 7.788860248795248,
    "total_flos": 4186844504832000,
    "step": 69500
  },
  {
    "loss": 3491.968,
    "learning_rate": 1.0775523926930404e-05,
    "epoch": 7.844895214613919,
    "total_flos": 4216965688320000,
    "step": 70000
  },
  {
    "eval_loss": 3499.091563432457,
    "epoch": 7.844895214613919,
    "total_flos": 4216965688320000,
    "step": 70000
  },
  {
    "loss": 3498.336,
    "learning_rate": 1.049534909783705e-05,
    "epoch": 7.90093018043259,
    "total_flos": 4247086871808000,
    "step": 70500
  },
  {
    "loss": 3497.568,
    "learning_rate": 1.0215174268743697e-05,
    "epoch": 7.956965146251261,
    "total_flos": 4277208055296000,
    "step": 71000
  },
  {
    "loss": 3479.584,
    "learning_rate": 9.934999439650343e-06,
    "epoch": 8.013000112069932,
    "total_flos": 4307329238784000,
    "step": 71500
  },
  {
    "loss": 3509.504,
    "learning_rate": 9.654824610556988e-06,
    "epoch": 8.069035077888602,
    "total_flos": 4337450422272000,
    "step": 72000
  },
  {
    "loss": 3494.752,
    "learning_rate": 9.374649781463633e-06,
    "epoch": 8.125070043707273,
    "total_flos": 4367571605760000,
    "step": 72500
  },
  {
    "loss": 3496.352,
    "learning_rate": 9.09447495237028e-06,
    "epoch": 8.181105009525945,
    "total_flos": 4397692789248000,
    "step": 73000
  },
  {
    "loss": 3514.144,
    "learning_rate": 8.814300123276926e-06,
    "epoch": 8.237139975344615,
    "total_flos": 4427813972736000,
    "step": 73500
  },
  {
    "loss": 3491.552,
    "learning_rate": 8.53412529418357e-06,
    "epoch": 8.293174941163286,
    "total_flos": 4457935156224000,
    "step": 74000
  },
  {
    "loss": 3503.392,
    "learning_rate": 8.253950465090217e-06,
    "epoch": 8.349209906981956,
    "total_flos": 4488056339712000,
    "step": 74500
  },
  {
    "loss": 3504.128,
    "learning_rate": 7.973775635996862e-06,
    "epoch": 8.405244872800628,
    "total_flos": 4518177523200000,
    "step": 75000
  },
  {
    "eval_loss": 3498.114808148097,
    "epoch": 8.405244872800628,
    "total_flos": 4518177523200000,
    "step": 75000
  },
  {
    "loss": 3512.256,
    "learning_rate": 7.693600806903508e-06,
    "epoch": 8.461279838619298,
    "total_flos": 4548298706688000,
    "step": 75500
  },
  {
    "loss": 3499.104,
    "learning_rate": 7.413425977810154e-06,
    "epoch": 8.51731480443797,
    "total_flos": 4578419890176000,
    "step": 76000
  },
  {
    "loss": 3504.928,
    "learning_rate": 7.133251148716799e-06,
    "epoch": 8.573349770256641,
    "total_flos": 4608541073664000,
    "step": 76500
  },
  {
    "loss": 3497.792,
    "learning_rate": 6.853076319623446e-06,
    "epoch": 8.62938473607531,
    "total_flos": 4638662257152000,
    "step": 77000
  },
  {
    "loss": 3495.552,
    "learning_rate": 6.572901490530091e-06,
    "epoch": 8.685419701893982,
    "total_flos": 4668783440640000,
    "step": 77500
  },
  {
    "loss": 3497.344,
    "learning_rate": 6.292726661436738e-06,
    "epoch": 8.741454667712652,
    "total_flos": 4698904624128000,
    "step": 78000
  },
  {
    "loss": 3498.752,
    "learning_rate": 6.0125518323433825e-06,
    "epoch": 8.797489633531324,
    "total_flos": 4729025807616000,
    "step": 78500
  },
  {
    "loss": 3491.264,
    "learning_rate": 5.732377003250029e-06,
    "epoch": 8.853524599349994,
    "total_flos": 4759146991104000,
    "step": 79000
  },
  {
    "loss": 3482.688,
    "learning_rate": 5.452202174156674e-06,
    "epoch": 8.909559565168665,
    "total_flos": 4789268174592000,
    "step": 79500
  },
  {
    "loss": 3506.496,
    "learning_rate": 5.172027345063319e-06,
    "epoch": 8.965594530987335,
    "total_flos": 4819389358080000,
    "step": 80000
  },
  {
    "eval_loss": 3496.800960572835,
    "epoch": 8.965594530987335,
    "total_flos": 4819389358080000,
    "step": 80000
  },
  {
    "loss": 3486.72,
    "learning_rate": 4.891852515969966e-06,
    "epoch": 9.021629496806007,
    "total_flos": 4849510541568000,
    "step": 80500
  },
  {
    "loss": 3497.472,
    "learning_rate": 4.611677686876611e-06,
    "epoch": 9.077664462624679,
    "total_flos": 4879631725056000,
    "step": 81000
  },
  {
    "loss": 3489.344,
    "learning_rate": 4.331502857783257e-06,
    "epoch": 9.133699428443348,
    "total_flos": 4909752908544000,
    "step": 81500
  },
  {
    "loss": 3499.328,
    "learning_rate": 4.0513280286899025e-06,
    "epoch": 9.18973439426202,
    "total_flos": 4939874092032000,
    "step": 82000
  },
  {
    "loss": 3505.984,
    "learning_rate": 3.7711531995965485e-06,
    "epoch": 9.24576936008069,
    "total_flos": 4969995275520000,
    "step": 82500
  },
  {
    "loss": 3469.184,
    "learning_rate": 3.4909783705031945e-06,
    "epoch": 9.301804325899361,
    "total_flos": 5000116459008000,
    "step": 83000
  },
  {
    "loss": 3505.344,
    "learning_rate": 3.2108035414098397e-06,
    "epoch": 9.357839291718031,
    "total_flos": 5030237642496000,
    "step": 83500
  },
  {
    "loss": 3490.816,
    "learning_rate": 2.9306287123164853e-06,
    "epoch": 9.413874257536703,
    "total_flos": 5060358825984000,
    "step": 84000
  },
  {
    "loss": 3508.608,
    "learning_rate": 2.6504538832231313e-06,
    "epoch": 9.469909223355375,
    "total_flos": 5090480009472000,
    "step": 84500
  },
  {
    "loss": 3498.688,
    "learning_rate": 2.370279054129777e-06,
    "epoch": 9.525944189174044,
    "total_flos": 5120601192960000,
    "step": 85000
  },
  {
    "eval_loss": 3496.054313368104,
    "epoch": 9.525944189174044,
    "total_flos": 5120601192960000,
    "step": 85000
  },
  {
    "loss": 3501.504,
    "learning_rate": 2.090104225036423e-06,
    "epoch": 9.581979154992716,
    "total_flos": 5150722376448000,
    "step": 85500
  },
  {
    "loss": 3493.376,
    "learning_rate": 1.8099293959430683e-06,
    "epoch": 9.638014120811386,
    "total_flos": 5180843559936000,
    "step": 86000
  },
  {
    "loss": 3491.904,
    "learning_rate": 1.5297545668497143e-06,
    "epoch": 9.694049086630057,
    "total_flos": 5210964743424000,
    "step": 86500
  },
  {
    "loss": 3507.776,
    "learning_rate": 1.24957973775636e-06,
    "epoch": 9.750084052448727,
    "total_flos": 5241085926912000,
    "step": 87000
  },
  {
    "loss": 3494.72,
    "learning_rate": 9.694049086630057e-07,
    "epoch": 9.806119018267399,
    "total_flos": 5271207110400000,
    "step": 87500
  },
  {
    "loss": 3503.808,
    "learning_rate": 6.892300795696514e-07,
    "epoch": 9.86215398408607,
    "total_flos": 5301328293888000,
    "step": 88000
  },
  {
    "loss": 3490.56,
    "learning_rate": 4.090552504762972e-07,
    "epoch": 9.91818894990474,
    "total_flos": 5331449477376000,
    "step": 88500
  },
  {
    "loss": 3500.608,
    "learning_rate": 1.2888042138294295e-07,
    "epoch": 9.974223915723412,
    "total_flos": 5361570660864000,
    "step": 89000
  }
]